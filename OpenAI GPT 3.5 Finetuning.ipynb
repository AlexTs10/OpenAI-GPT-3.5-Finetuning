{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826fae45-bcf9-4bc5-8b56-bb12defc64c7",
   "metadata": {},
   "source": [
    "## This notebook shows how to finetune OpenAI GPT3.5 Model -with 1 command- on the Mental Health Chat Dataset from HugginFace [here](https://huggingface.co/datasets/heliosbrahma/mental_health_chatbot_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92865b1-c7af-490b-bbbd-8c8ab4fc82ec",
   "metadata": {},
   "source": [
    "**Note:** The process is simple and OpenAI charges only for the amount of tokens that will pass through the model in training.\n",
    "Although the cost of using the finetuned model is 10x the cost of the GPT3.5 and 1/3 the cost of GPT 4. \n",
    "Finetuning should be the last option in any project!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d48ab-ead7-4ef5-8a31-6e5e43b85777",
   "metadata": {},
   "source": [
    "### Step 0: Import all Libraries and set API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4948cb8c-d35d-4269-af54-7ddcd78230b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"sk-xxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c42e2a-f0bd-4828-ad47-513d8cb22706",
   "metadata": {},
   "source": [
    "### Step 1: Download Dataset and Format It\n",
    "\n",
    "- You can download the dataset directly from the Hub but it is a small dataset so i will just download the parquet file and import with pandas\n",
    "- Originally it has one column but i will add a second one that will be fed to openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3327f1c8-9852-4e76-8fb7-c98389730eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_openai_formated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;HUMAN&gt;: What is a panic attack?\\n&lt;ASSISTANT&gt;:...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;HUMAN&gt;: What are symptoms of panic attack vs....</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;HUMAN&gt;: What are the types of Mental Illness?...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;HUMAN&gt;: What does mental-illness mean?\\n&lt;ASSI...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;HUMAN&gt;: How can you treat mental illness?\\n&lt;A...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text text_openai_formated\n",
       "0  <HUMAN>: What is a panic attack?\\n<ASSISTANT>:...                 None\n",
       "1  <HUMAN>: What are symptoms of panic attack vs....                 None\n",
       "2  <HUMAN>: What are the types of Mental Illness?...                 None\n",
       "3  <HUMAN>: What does mental-illness mean?\\n<ASSI...                 None\n",
       "4  <HUMAN>: How can you treat mental illness?\\n<A...                 None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('train-mental.parquet')\n",
    "df['text_openai_formated'] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "256ff2e9-9f8d-478c-981c-0163e6a1e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest string contains 369 words approximately 527 tokens.\n",
      "GPT 3.5 has a context length of 4096 tokens so no problem here\n"
     ]
    }
   ],
   "source": [
    "# check the biggest length of prompts\n",
    "n_max_words = 0\n",
    "for index, row in df.iterrows():\n",
    "    n_max_words = max(n_max_words, len(row['text'].split()))\n",
    "\n",
    "print(f\"The longest string contains {n_max_words} words approximately {round(n_max_words/0.7)} tokens.\")  \n",
    "print(\"GPT 3.5 has a context length of 4096 tokens so no problem here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13408ed-df15-4b76-9e15-da4605fea86f",
   "metadata": {},
   "source": [
    "### System Message \n",
    "\n",
    "- The system prompt works as a guide to what our model want to talk and act like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1a94131-2b9a-4b77-8bd7-45065eaf324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoctorGPT is a factual chatbot that is an expert on mental health. He's mission is to help the user all the time and never refuse to answer.\n"
     ]
    }
   ],
   "source": [
    "sys_msg = \"DoctorGPT is a factual chatbot that is an expert on mental health. He's mission is to help the user all the time and never refuse to answer.\"\n",
    "print(sys_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c99a8c-0cde-4b44-ad20-53aa155c7df4",
   "metadata": {},
   "source": [
    "### Transform the Data into the format OpenAI requires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35b77f-48b0-4421-8093-f1368f40af4a",
   "metadata": {},
   "source": [
    "<code>{\"messages\": [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": User_Input}, {\"role\": \"assistant\", \"content\": Model_Outout}]} </code>``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828eb63-0e8c-426c-9847-a2862fdc5d65",
   "metadata": {},
   "source": [
    "<code>{\"messages\": [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": User_Input}, {\"role\": \"assistant\", \"content\": Model_Outout}]} </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97260d2b-f977-4cd1-8f63-9d0630212cae",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5ef14-d8fc-4421-91f3-6ab58ea8f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "\n",
    "    assistant_keyword = \"<ASSISTANT>: \"\n",
    "    human_keyword = \"<HUMAN>: \"\n",
    "\n",
    "    # Find the index of the keyword in the text\n",
    "    idx = text.index(assistant_keyword)\n",
    "\n",
    "    human_msg = text[:idx].replace(human_keyword, '')\n",
    "    assistant_msg = text[idx:].replace(assistant_keyword, '')\n",
    "\n",
    "    data = {\"messages\": [{\"role\": \"system\", \"content\": sys_msg}, \n",
    "                                                             {\"role\": \"user\", \"content\": human_msg}, \n",
    "                                                             {\"role\": \"assistant\", \"content\": assistant_msg}]}\n",
    "    df.at[index, 'text_openai_formated'] = data\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b27b67b-49bd-489e-bc37-8597b64ea516",
   "metadata": {},
   "source": [
    "### Save the Transformed Data in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b49cd410-66f5-4729-9c66-1fc9a4494d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each element of the list on a separate line in the JSON file\n",
    "with open('test.json', 'w') as json_file:\n",
    "    for item in data_list:\n",
    "        json_file.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b5edc-4023-4f1c-86b7-65c2fe7a726a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb7ce22c-e408-43cc-b023-e1818e4618e6",
   "metadata": {},
   "source": [
    "### OpenAI Script to validate the data and provide Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3035da5b-e6a5-452d-819a-b2ee319772fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 172\n",
      "First example:\n",
      "{'role': 'system', 'content': \"DoctorGPT is a factual chatbot that is an expert on mental health. He's mission is to help the user all the time and never refuse to answer.\"}\n",
      "{'role': 'user', 'content': 'What is a panic attack?\\n'}\n",
      "{'role': 'assistant', 'content': 'Panic attacks come on suddenly and involve intense and often overwhelming fear. Theyâ€™re accompanied by very challenging physical symptoms, like a racing heartbeat, shortness of breath, or nausea. Unexpected panic attacks occur without an obvious cause. Expected panic attacks are cued by external stressors, like phobias. Panic attacks can happen to anyone, but having more than one may be a sign of panic disorder, a mental health condition characterized by sudden and repeated panic attacks.'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 83, 528\n",
      "mean / median: 248.26162790697674, 235.5\n",
      "p5 / p95: 130.3, 385.9\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 29, 469\n",
      "mean / median: 189.02906976744185, 178.0\n",
      "p5 / p95: 73.2, 325.8\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~42701 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~128103 tokens\n",
      "See pricing page to estimate total costs\n",
      "Cost: ~ 1.02 $\n"
     ]
    }
   ],
   "source": [
    "# Next, we specify the data path and open the JSONL file\n",
    "data_path = \"test.json\"\n",
    "\n",
    "# Load dataset\n",
    "with open(data_path) as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# We can inspect the data quickly by checking the number of examples and the first item\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")\n",
    "\n",
    "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
    "\n",
    "# Token counting functions\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
    "\n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_EPOCHS = 1\n",
    "MAX_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "print(\"See pricing page to estimate total costs\")\n",
    "print(f\"Cost: ~ {round(n_epochs * (n_billing_tokens_in_dataset/1000) * 0.008, 2)} $\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3a9d9-0111-4112-a726-c52009d4c0cf",
   "metadata": {},
   "source": [
    "## Step 2: Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76dcaa28-2c28-4096-b9e5-3a5f7bc589aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-Cj0rMqbIvuSAxdGUAW4iqfU6 at 0x7f3f88a9a840> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-Cj0rMqbIvuSAxdGUAW4iqfU6\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 231260,\n",
       "  \"created_at\": 1693155705,\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"test.json\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d4389-7c51-4524-8e67-4067de48276e",
   "metadata": {},
   "source": [
    "## Step 3: Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "689865b4-0706-4e5f-8c77-c8b81aa6390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below \n",
    "\n",
    "#openai.FineTuningJob.create(training_file=\"file-px68T9xYyYCZe3aFfZXCixIz\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e420c43-61ee-4323-9ee6-65e0b79c0a3f",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "<FineTuningJob fine_tuning.job id=ftjob-xxxx at 0x7f9b7ea5ac50> JSON: {\n",
    "  \"object\": \"fine_tuning.job\",\n",
    "  \"id\": \"ftjob-xxxx\",\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"created_at\": 1692968797,\n",
    "  \"finished_at\": null,\n",
    "  \"fine_tuned_model\": null,\n",
    "  \"organization_id\": \"org-xxxxx\",\n",
    "  \"result_files\": [],\n",
    "  \"status\": \"created\",\n",
    "  \"validation_file\": null,\n",
    "  \"training_file\": \"file-px68T9xYyYCZe3aFfZXCixIz\",\n",
    "  \"hyperparameters\": {\n",
    "    \"n_epochs\": 3\n",
    "  },\n",
    "  \"trained_tokens\": null\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0572b-c832-4210-97ed-9dbd61129e0d",
   "metadata": {},
   "source": [
    "Now we wait. This job will take less than 10 minutes but required time can vary a lot !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c1bb44b-8de5-4182-8803-b103d0e9d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "# print(openai.FineTuningJob.list(limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17120db3-4fa2-42bc-8f9b-0ed3fe579d93",
   "metadata": {},
   "source": [
    "<pre>\n",
    "{\n",
    "  \"object\": \"list\",\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"object\": \"fine_tuning.job\",\n",
    "      \"id\": \"ftjob-QnlC2wyVRTs3RHgtvvmAF8na\",\n",
    "      \"model\": \"gpt-3.5-turbo-0613\",\n",
    "      \"created_at\": 1692968797,\n",
    "      \"finished_at\": 1692969848,\n",
    "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7rR5CkYd\",\n",
    "      \"organization_id\": \"org-XhR0hBmBoQbi9SrGpldtXXkJ\",\n",
    "      \"result_files\": [\n",
    "        \"file-CJmiIUHofIxBmwLLE7OIuaOE\"\n",
    "      ],\n",
    "      \"status\": \"succeeded\",\n",
    "      \"validation_file\": null,\n",
    "      \"training_file\": \"file-px68T9xYyYCZe3aFfZXCixIz\",\n",
    "      \"hyperparameters\": {\n",
    "        \"n_epochs\": 3\n",
    "      },\n",
    "      \"trained_tokens\": 127071\n",
    "    }\n",
    "  ],\n",
    "  \"has_more\": false\n",
    "} \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f3cc6-e8f6-4f50-a240-2e8b281de4cc",
   "metadata": {},
   "source": [
    "### You can check the progress by running the cell bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2d6150b-a06f-4707-bc87-b638b26a6fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f3f651c8a90> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-rVMzY4UlM9l8QjsHWcjd5cj9\",\n",
       "      \"created_at\": 1692969849,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tuning job successfully completed\",\n",
       "      \"data\": null,\n",
       "      \"type\": \"message\"\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-L95faZTJY42wKQENj17ox9Of\",\n",
       "      \"created_at\": 1692969846,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal::7rR5CkYd\",\n",
       "      \"data\": null,\n",
       "      \"type\": \"message\"\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": true\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List up to 10 events from a fine-tuning job\n",
    "openai.FineTuningJob.list_events(id=\"ftjob-xxxx\", limit=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a14c4a-3a33-46ab-ba6a-7539e8c8fbe1",
   "metadata": {},
   "source": [
    "## Step 4 Use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635da0d-0bd9-4bd4-bd19-9ac43c28affd",
   "metadata": {},
   "source": [
    "### Once you see `\"message\": \"Fine-tuning job successfully completed\"` you are ready to use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c2e63-0b69-4e26-a1fd-60d8a5fb7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"ft:gpt-3.5-turbo:my-org:custom_suffix:id\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44377ff6-0df6-41a2-9379-49f5e9f4efa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0724699-2c95-4f5d-b7e1-1fd984665599",
   "metadata": {},
   "source": [
    "### Extra Tips\n",
    "\n",
    "- Cancel a job\n",
    "- Delete a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81abc6-8280-40cf-bc7e-ee2687542d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel a job\n",
    "openai.FineTuningJob.cancel(\"ft-abc123\")\n",
    "\n",
    "openai.Model.delete(\"ft-abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d4072-6756-48f1-b9a3-a2216abc4905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5848e94-cad6-453c-9290-cf43015c7908",
   "metadata": {},
   "source": [
    "### Check my Github for more: [here](https://github.com/AlexTs10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82243a3-7bef-4509-8868-df64c9280519",
   "metadata": {},
   "source": [
    "### Are you looking for an AI Developer ?? contact here -> alextoska1010@protonmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde64593-9bb0-4bf2-943c-01e2a8ebe19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
